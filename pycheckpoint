import os
import fitz  # pymupdf
import io
from PIL import Image
from pathlib import Path
import google.generativeai as genai
from pinecone import Pinecone, ServerlessSpec
import boto3
from botocore.exceptions import ClientError
from dotenv import load_dotenv
import hashlib
import time
from typing import List, Dict

load_dotenv()

# API Keys & config
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT", "us-east-1")
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_REGION", "us-east-1")
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")

if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY not found in .env file.")
if not PINECONE_API_KEY:
    raise ValueError("PINECONE_API_KEY not found in .env file.")
if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:
    raise ValueError("AWS credentials not found in .env file.")
if not S3_BUCKET_NAME:
    raise ValueError("S3_BUCKET_NAME not found in .env file.")

# Configure Google AI
genai.configure(api_key=GEMINI_API_KEY)

# --- Configuration ---
GENERATION_MODEL_NAME = "gemini-2.5-flash"
EMBEDDING_MODEL_NAME = "models/text-embedding-004"
EMBEDDING_DIMENSION = 768  # expected dimension of the embedding model
CHUNK_SIZE = 800           # approx characters per chunk (adjustable)
CHUNK_OVERLAP = 150        # overlap in characters
UPSERT_BATCH = 100         # how many vectors to upsert per request

# Local temp directory
DATA_DIR = Path(os.getenv("DATA_DIR", "."))
TEMP_DIR = DATA_DIR / "temp"
TEMP_DIR.mkdir(parents=True, exist_ok=True)

# Initialize Google AI generation model
try:
    generation_model = genai.GenerativeModel(GENERATION_MODEL_NAME)
except Exception as e:
    print(f"Error initializing Google AI generation model: {e}")
    raise

# Initialize Pinecone
try:
    pc = Pinecone(api_key=PINECONE_API_KEY)

    index_name_text = "invensight-text"
    index_name_images = "invensight-images"

    existing_indexes = [index.name for index in pc.list_indexes()]

    if index_name_text not in existing_indexes:
        pc.create_index(
            name=index_name_text,
            dimension=EMBEDDING_DIMENSION,
            metric="cosine",
            spec=ServerlessSpec(cloud="aws", region=PINECONE_ENVIRONMENT)
        )

    if index_name_images not in existing_indexes:
        pc.create_index(
            name=index_name_images,
            dimension=EMBEDDING_DIMENSION,
            metric="cosine",
            spec=ServerlessSpec(cloud="aws", region=PINECONE_ENVIRONMENT)
        )

    text_index = pc.Index(index_name_text)
    image_index = pc.Index(index_name_images)

    print("Pinecone initialized successfully")
except Exception as e:
    print(f"Error initializing Pinecone: {e}")
    raise

# Initialize S3
try:
    s3_client = boto3.client(
        's3',
        aws_access_key_id=AWS_ACCESS_KEY_ID,
        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
        region_name=AWS_REGION
    )

    try:
        s3_client.head_bucket(Bucket=S3_BUCKET_NAME)
    except ClientError:
        s3_client.create_bucket(
            Bucket=S3_BUCKET_NAME,
            CreateBucketConfiguration={'LocationConstraint': AWS_REGION} if AWS_REGION != 'us-east-1' else {}
        )

    print("S3 initialized successfully")
except Exception as e:
    print(f"Error initializing S3: {e}")
    raise

# --- Utilities ---

def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:
    """
    Split text into chunks of approximately chunk_size characters with overlap.
    Keeps sentences reasonably intact by splitting on sentence boundaries when possible.
    """
    if not text:
        return []

    # Normalize whitespace
    txt = " ".join(text.split())
    # Try to split on common sentence separators to preserve sentence boundaries
    import re
    sentences = re.split(r'(?<=[\.\?\!])\s+', txt)
    chunks = []
    current = ""
    for sent in sentences:
        if len(current) + len(sent) + 1 <= chunk_size:
            current = (current + " " + sent).strip()
        else:
            if current:
                chunks.append(current)
            # If sentence itself larger than chunk_size, break it forcefully
            if len(sent) > chunk_size:
                # break into raw substrings
                start = 0
                while start < len(sent):
                    chunks.append(sent[start:start + chunk_size].strip())
                    start += chunk_size - overlap
                current = ""
            else:
                current = sent
    if current:
        chunks.append(current)

    # Add explicit overlap windows to improve retrieval context continuity
    if overlap and len(chunks) > 1:
        overlapped = []
        for i in range(len(chunks)):
            start_idx = max(0, i - 1)
            window = " ".join(chunks[start_idx:i+1])
            overlapped.append(window)
        return overlapped
    return chunks

def generate_file_hash(file_path: Path) -> str:
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def upload_to_s3(file_path: Path, s3_key: str) -> str:
    try:
        s3_client.upload_file(str(file_path), S3_BUCKET_NAME, s3_key)
        s3_uri = f"s3://{S3_BUCKET_NAME}/{s3_key}"
        print(f"Uploaded {file_path.name} to {s3_uri}")
        return s3_uri
    except Exception as e:
        print(f"Error uploading to S3: {e}")
        return ""

def download_from_s3(s3_key: str, local_path: Path) -> bool:
    try:
        s3_client.download_file(S3_BUCKET_NAME, s3_key, str(local_path))
        print(f"Downloaded {s3_key} from S3")
        return True
    except Exception as e:
        print(f"Error downloading from S3: {e}")
        return False

# --- Embeddings with retries and validation ---
def get_text_embedding(text: str, retries: int = 3, backoff: float = 1.0):
    """Stable embedding generator with retries and dimension check."""
    if not text:
        return None
    for attempt in range(1, retries + 1):
        try:
            result = genai.embed_content(model=EMBEDDING_MODEL_NAME, content=text)
            embedding = result.get('embedding')
            if not embedding:
                raise ValueError("No 'embedding' in response")
            if len(embedding) != EMBEDDING_DIMENSION:
                print(f"⚠️ Embedding dimension mismatch: expected {EMBEDDING_DIMENSION}, got {len(embedding)}")
                # continue to retry once or fall back
                time.sleep(backoff * attempt)
                continue
            return embedding
        except Exception as e:
            print(f"Embedding attempt {attempt} failed: {e}")
            time.sleep(backoff * attempt)
    print("Failed to generate embedding after retries.")
    return None

# --- Image description ---
IMAGE_DESCRIPTION_PROMPT = """Explain what is going on in the image.
If it's a table, extract the table content as text.
If it's a graph, explain the findings in the graph.
Do not invent numbers not present in the image.
Keep description concise (max 200 words).
"""

def get_image_description(pil_image: Image.Image):
    try:
        # Keep it text-only for metadata; generation_model may accept images depending on SDK.
        # If SDK supports multimodal input, the SDK call may vary — this keeps it robust.
        response = generation_model.generate_content([IMAGE_DESCRIPTION_PROMPT, pil_image])
        return response.text.strip()
    except Exception as e:
        print(f"Error generating image description: {e}")
        return ""

# --- Processing pipeline ---
def process_user_files(user_id: str, pdf_path: Path):
    """
    Processes a single uploaded PDF:
    - Upload PDF to S3
    - Chunk text and embed each chunk with metadata
    - Extract images, describe them, embed descriptions
    - Batch upsert vectors to Pinecone
    """
    print(f"Starting processing for user: {user_id}, file: {pdf_path.name}")

    file_hash = generate_file_hash(pdf_path)

    s3_key_pdf = f"users/{user_id}/pdfs/{pdf_path.name}"
    s3_uri_pdf = upload_to_s3(pdf_path, s3_key_pdf)
    if not s3_uri_pdf:
        print("Failed to upload PDF to S3")
        return

    text_vectors = []
    image_vectors = []

    try:
        doc = fitz.open(pdf_path)
        print(f"Opened document: {pdf_path.name}")

        for page_num, page in enumerate(doc):
            # Text extraction & chunking
            page_text = page.get_text()
            if page_text and page_text.strip():
                chunks = chunk_text(page_text)
                total_chunks = len(chunks)
                for chunk_index, chunk in enumerate(chunks):
                    # Enrich chunk with file anchor
                    anchored_chunk = f"Document: {pdf_path.name}\nPage: {page_num+1}\n{textwrap_short(chunk)}"
                    emb = get_text_embedding(anchored_chunk)
                    if not emb:
                        continue
                    vector_id = f"{user_id}_{file_hash}_text_p{page_num+1}_c{chunk_index}"
                    metadata = {
                        "user_id": user_id,
                        "file_name": pdf_path.name,
                        "file_hash": file_hash,
                        "s3_uri": s3_uri_pdf,
                        "page_number": page_num + 1,
                        "type": "text",
                        "chunk_index": chunk_index,
                        "total_chunks": total_chunks,
                        "preview": chunk[:800]
                    }
                    text_vectors.append({"id": vector_id, "values": emb, "metadata": metadata})

            # Image extraction
            for img_index, img_info in enumerate(page.get_images(full=True)):
                xref = img_info[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image.get("image")
                if not image_bytes:
                    continue
                pil_image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

                temp_img_name = f"{pdf_path.stem}_p{page_num+1}_img{img_index}.png"
                temp_img_path = TEMP_DIR / temp_img_name
                pil_image.save(temp_img_path)

                s3_key_img = f"users/{user_id}/images/{temp_img_name}"
                s3_uri_img = upload_to_s3(temp_img_path, s3_key_img)

                img_desc = get_image_description(pil_image)
                if img_desc and s3_uri_img:
                    anchored_desc = f"Document: {pdf_path.name}\nPage: {page_num+1}\n{img_desc}"
                    desc_emb = get_text_embedding(anchored_desc)
                    if desc_emb:
                        vector_id = f"{user_id}_{file_hash}_img_p{page_num+1}_i{img_index}"
                        metadata = {
                            "user_id": user_id,
                            "file_name": pdf_path.name,
                            "file_hash": file_hash,
                            "s3_uri_pdf": s3_uri_pdf,
                            "s3_uri_image": s3_uri_img,
                            "page_number": page_num + 1,
                            "type": "image",
                            "image_index": img_index,
                            "description_preview": img_desc[:800]
                        }
                        image_vectors.append({"id": vector_id, "values": desc_emb, "metadata": metadata})

                # cleanup temp image file
                try:
                    temp_img_path.unlink(missing_ok=True)
                except Exception:
                    pass

        # close doc
        doc.close()

        # Batch upsert helper
        def batch_upsert(index, items):
            for i in range(0, len(items), UPSERT_BATCH):
                batch = items[i:i + UPSERT_BATCH]
                try:
                    index.upsert(vectors=batch, namespace=user_id)
                except Exception as e:
                    print(f"Error upserting batch: {e}")

        if text_vectors:
            batch_upsert(text_index, text_vectors)
            print(f"Uploaded {len(text_vectors)} text vectors to Pinecone")

        if image_vectors:
            batch_upsert(image_index, image_vectors)
            print(f"Uploaded {len(image_vectors)} image vectors to Pinecone")

        print(f"Finished processing file for user: {user_id}")

    except Exception as e:
        print(f"Error processing file for user {user_id}: {e}")
        raise

# small utility: shorten long text safely for anchored chunk to reduce API size
def textwrap_short(text: str, limit: int = 2000) -> str:
    if not text:
        return ""
    return text if len(text) <= limit else text[:limit] + " ..."

# --- Querying pipeline ---
def query_user_data(user_id: str, query: str, top_k: int = 10):
    """
    Queries Pinecone (text + image indices), merges and reranks by Pinecone scores,
    constructs a structured prompt (text + image captions + s3 links), and asks Gemini.
    """
    query_emb = get_text_embedding(query)
    if not query_emb:
        return "Error: Could not generate embedding for query."

    try:
        text_results = text_index.query(vector=query_emb, top_k=top_k, namespace=user_id, include_metadata=True)
        image_results = image_index.query(vector=query_emb, top_k=top_k, namespace=user_id, include_metadata=True)

        print(f"Text matches: {len(text_results.matches)}; Image matches: {len(image_results.matches)}")

        if not text_results.matches and not image_results.matches:
            return ("I don't have any documents to search through yet.\n\n"
                    "Possible reasons:\n"
                    "1. Your document is still being processed\n"
                    "2. No documents uploaded yet\n"
                    "3. The document upload may have failed\n\n"
                    "Please upload a document or try again later.")

        # Merge results and sort by score (Pinecone uses cosine; higher is more similar)
        merged = []
        for m in (text_results.matches or []):
            merged.append((m.score, "text", m.metadata))
        for m in (image_results.matches or []):
            merged.append((m.score, "image", m.metadata))
        merged.sort(key=lambda x: x[0], reverse=True)

        # Build final context using top N merged items
        context_parts = []
        for score, typ, meta in merged[:min(12, len(merged))]:
            if typ == "text":
                preview = meta.get("preview") or meta.get("content") or ""
                context_parts.append(f"[Text] (score: {score:.3f}) Source: {meta.get('file_name')} - Page {meta.get('page_number')}\n{preview}")
            else:
                desc = meta.get("description_preview") or meta.get("description") or ""
                s3_img = meta.get("s3_uri_image") or meta.get("s3_uri")
                context_parts.append(f"[Image] (score: {score:.3f}) Source: {meta.get('file_name')} - Page {meta.get('page_number')}\nDescription: {desc}\nS3: {s3_img}")

        final_context = "\n\n---\n\n".join(context_parts) if context_parts else "No relevant context found."

        # Structured prompt
        prompt = f"""
You are InvenSight Assistant. Use only the CONTEXT below (text snippets and image descriptions) to answer the QUESTION. Try your best to answer the query. If unable to do so, say "Sorry, not able to process this query."

CONTEXT:
{final_context}

QUESTION:
{query}

FINAL ANSWER:
"""
        # Ask Gemini
        response = generation_model.generate_content([prompt])
        return response.text

    except Exception as e:
        print(f"Error querying data for user {user_id}: {e}")
        return f"Error: {e}"

# --- File listing & deletion (unchanged logic but robustified) ---
def list_user_files(user_id: str) -> List[Dict]:
    try:
        prefix = f"users/{user_id}/pdfs/"
        response = s3_client.list_objects_v2(Bucket=S3_BUCKET_NAME, Prefix=prefix)
        files = []
        if 'Contents' in response:
            for obj in response['Contents']:
                files.append({
                    "file_name": obj['Key'].split('/')[-1],
                    "s3_key": obj['Key'],
                    "size": obj['Size'],
                    "last_modified": obj['LastModified'].isoformat()
                })
        return files
    except Exception as e:
        print(f"Error listing files: {e}")
        return []

def delete_user_file(user_id: str, file_name: str):
    try:
        s3_key = f"users/{user_id}/pdfs/{file_name}"
        s3_client.delete_object(Bucket=S3_BUCKET_NAME, Key=s3_key)

        prefix = f"users/{user_id}/images/{Path(file_name).stem}"
        response = s3_client.list_objects_v2(Bucket=S3_BUCKET_NAME, Prefix=prefix)
        if 'Contents' in response:
            for obj in response['Contents']:
                s3_client.delete_object(Bucket=S3_BUCKET_NAME, Key=obj['Key'])

        text_index.delete(filter={"user_id": user_id, "file_name": file_name}, namespace=user_id)
        image_index.delete(filter={"user_id": user_id, "file_name": file_name}, namespace=user_id)

        print(f"Deleted file {file_name} for user {user_id}")
        return True
    except Exception as e:
        print(f"Error deleting file: {e}")
        return False